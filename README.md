# OllamaHub - web UI for Ollama

### ‚≠ê Main features

- Chating with Ollama models via web UI 
- Storing all data locally on your browser
- Streaming response in real-time
- Markdown parsing with syntax highlighting
- Installing models via web UI

## üßê How to use?
1. Install [Ollama](https://ollama.com/download)
2. Go to the [web app](https://ollama-hub.vercel.app) (no registration required)
3. Install model you want ([Full list of models](https://ollama.com/models))
4. Enjoy!

## üîß Tech stack

- TypeScript 
- React
- Zustand + Persist
- TanStack Router
- Tailwind CSS
- RadixUI
- Framer Motion
- Vite

## üèÉ Get started locally

1. Install [Ollama](https://ollama.com/download)
2. Clone the repo on your computer
3. `npm i`
4. `npm run build && npm run preview`
